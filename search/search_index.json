{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"ADS Root Cause Analysis","text":"<p>Here is the documents of project ADS Root Cause Analysis. This project is based on MoDitector: Module-Directed Testing for Autonomous Driving Systems</p> <p>This project aims to build a framework to analyze the ADS running logs, to figure out which module should be responded to the failure of running.</p>"},{"location":"#installation","title":"Installation","text":"<p>Clone the repo from github by</p> <pre><code>git clone https://github.com/Shanicky-RenzhiWang/ADSRootCauseAnaylsis.git\n</code></pre> <p>Install the requirements</p> <pre><code>cd ADSRootCauseAnaylsis\npip install -r requirements\n</code></pre>"},{"location":"#quick-start","title":"Quick Start","text":"<p>Once the installation completed, the project is already usable.</p> <p>The details for running can be found in the How to Run label. </p> <p>We provide examples for running, download it by</p> <pre><code>bash get_data.sh\n</code></pre> <p>Then execute</p> <pre><code>python main.py log_dir=examples/example_collision\n</code></pre> <p>to run the first example.</p>"},{"location":"HowTo/","title":"How to Run","text":"<p>To run this project, you need to provide the analysis base configuration and log information at runtime. Their structure is as follows.</p>"},{"location":"HowTo/#base-configuration","title":"Base Configuration","text":"<p>The base configuration defines the parameters required during the analysis process, including the time window for analysis and the specific settings for each module, as shown below:</p>"},{"location":"HowTo/#example-configuration-configrcanaylsisyaml","title":"\ud83d\udd27 Example Configuration (<code>config/RCanaylsis.yaml</code>)","text":"<pre><code>log_dir: /path/to/logs\neffect_time_window: 10\nmodule_setting:\nperception:\n    perc_score_threshold: 0.5\nprediction:\n    prediction_window: 10\n    pred_score_threshold: 0.1\nplanning:\n    planning_toleration_future_step: 5\n    planning_toleration: 1\n</code></pre> <p>Explanation of Configuration Fields</p>"},{"location":"HowTo/#explanation-of-configuration-fields","title":"\ud83d\udcdd Explanation of Configuration Fields","text":"<ul> <li><code>log_dir</code>: Path to the input log directory.</li> <li> <p><code>effect_time_window</code>: Time window (in frames) to consider for root cause analysis.</p> </li> <li> <p><code>module_setting</code>:</p> <ul> <li><code>perception.perc_score_threshold</code>: Minimum confidence score for the perception module to consider a result valid.</li> <li><code>prediction.prediction_window</code>: Time horizon (in frames) used by the prediction module(If it differs from the settings of the running prediction module, the smaller value between the two will be used by default.).</li> <li><code>prediction.pred_score_threshold</code>: Confidence threshold for predictions to be considered reliable.</li> <li><code>planning.planning_toleration_future_step</code>: The planner allows a small tolerance for errors after a number of future steps.</li> <li><code>planning.planning_toleration</code>: Tolerance value for planning errors (in meters).</li> </ul> </li> </ul>"},{"location":"HowTo/#custom-configuration","title":"Custom Configuration","text":"<p>If you need to set the analysis configurations, there are two ways to do so:</p> <ol> <li> <p>Directly modify the project's default configuration file. <code>{project}/ADSRootCauseAnalysis/config/RCanalysis.yaml</code></p> </li> <li> <p>(Recommended) Create a custom configuration file and specify it at runtime.</p> </li> </ol> <p>You can create a new configuration file with same format, and running with</p> <pre><code>python main.py --config-path &lt;your/file/path&gt; --config-name &lt;your/file/name&gt;\n</code></pre>"},{"location":"HowTo/#input-data","title":"Input Data","text":"<p>The input data of ADS Root Cause Anaylsis is the running log of ADS, the details can be found in Input Format.</p>"},{"location":"HowTo/#standalone-running","title":"Standalone Running","text":"<p>This project can be run as a standalone application or imported as a Python package for integration into other projects.</p> <p>In summary, <code>RCHandler</code> wraps all core functionalities and enables standalone execution by importing and using this class directly. To run this package, you need to create a configuration file as an OmegaConf <code>DictConfig</code> and pass it as a parameter to initialize the <code>RCHandler</code>.</p> <pre><code>from ADSRootCauseAnalysis import RCHandler\nfrom omegaconf import DictConfig\nfrom hydra import initialize, compose\n\n... your code\n\nwith initialize(config_path=\"ADSRootCauseAnaylsis/config\"):\n    cfg = compose(config_name=\"RCanaylsis\")\n    RCHandler(cfg)\n</code></pre>"},{"location":"Input/","title":"Input Format","text":""},{"location":"Input/#metadata","title":"Metadata","text":"<p>The metadata is the basic information of the running logs as </p> <pre><code>{\n    \"timesteps_per_frame\": 50,\n    \"ego_config\":{\n        \"camera\":{\n            \"camera_loc\" : [1.3, 0.0, 1.8]\n        }\n    },\n    \"collision_frame\": 114,\n    \"total_frames\": 114\n}\n</code></pre> <ul> <li><code>timesteps_per_frame</code>: Number of millisecond per frame (e.g. 50 millisecond/frame)</li> <li><code>ego_config</code><ul> <li><code>camera</code><ul> <li><code>camera_loc</code>: Camera position coordinates [x,y,z] in meters (e.g. [1.3, 0.0, 1.8])</li> </ul> </li> </ul> </li> <li><code>timesteps_per_frame</code>: Frame number where collision occurs</li> <li><code>total_frames</code>: Total number of frames in simulation</li> </ul>"},{"location":"Input/#running-logs","title":"Running Logs","text":"<p>ADS Root Cause Analysis is to analyze the running logs of ADS, thus the following logs are needed. Each piece of data is in JSON format and should be placed in the corresponding folder. The file name should follow the pattern <code>xxx-ttt.json</code>, where <code>xxx</code> is the data name and <code>ttt</code> is the timestamp in milliseconds.</p>"},{"location":"Input/#pose","title":"Pose","text":"<p>The Pose data records the ego car's operating state at each moment, collected from either the simulator or the real world.</p> <p>The Pose data saved in <code>${input_data}/pose/pose-ttt.json</code>. A typical pose data should like</p> <pre><code>{\n    \"x\": \"-111.38536071777345\",\n    \"y\": \"2.82016420293382\",\n    \"z\": \"0.03314319625496864\",\n    \"pitch\": \"0\",\n    \"yaw\": \"-0.1394016564817946\",\n    \"roll\": \"0\",\n    \"timestamp\": \"50\",\n    \"speed\": \"1.959183287133675\"\n}\n</code></pre> <ul> <li><code>x</code>: The X-coordinate position in 3D space (in meters).</li> <li><code>y</code>: The Y-coordinate position in 3D space (in meters).</li> <li><code>z</code>: The Z-coordinate position in 3D space (in meters).</li> <li><code>pitch</code>: The pitch angle representing the rotation around the lateral axis (up/down tilt),in degrees.</li> <li><code>yaw</code>: The yaw angle representing the rotation around the vertical axis (left/right turn), in degrees.</li> <li><code>roll</code>: The roll angle representing the rotation around the longitudinal axis (tilting side to side), in degrees.</li> <li><code>timestamp</code>: The time at which the data was recorded, given in milliseconds.</li> <li><code>speed</code>: The instantaneous speed of the object at this timestamp, in meters per second.</li> </ul>"},{"location":"Input/#actors","title":"Actors","text":"<p>The Actors data records all vehicles and pedstrains in the environment, collected from either the simulator or the real world.</p> <p>The Actors data saved in <code>${input_data}/actors/actors-ttt.json</code>. A typical actor data should like</p> <pre><code>{\n    \"746\": {\n        \"extent\": {\n            \"x\": 2.4508416652679443,\n            \"y\": 1.0641621351242065,\n            \"z\": 0.7553732395172119\n        },\n        \"location\": {\n            \"x\": -111.38536071777344,\n            \"y\": 2.820164203643799,\n            \"z\": 0.03314319625496864\n        },\n        \"rotation\": {\n            \"pitch\": 0.0021241887006908655,\n            \"roll\": -0.003143310546875,\n            \"yaw\": -0.139404296875\n        }\n    },\n    ...\n}\n</code></pre> <ul> <li><code>keyValue</code>: The actor's id.</li> <li><code>extent</code>:<ul> <li><code>x</code>: The half X-coordinate extent of actor (in meters).</li> <li><code>y</code>: The half Y-coordinate extent of actor (in meters).</li> <li><code>z</code>: The half Z-coordinate pextent of actor (in meters).</li> </ul> </li> <li><code>location</code><ul> <li><code>x</code>: The X-coordinate position in 3D space (in meters).</li> <li><code>y</code>: The Y-coordinate position in 3D space (in meters).</li> <li><code>z</code>: The Z-coordinate position in 3D space (in meters).</li> </ul> </li> <li><code>rotation</code><ul> <li><code>pitch</code>: The pitch angle representing the rotation around the lateral axis (up/down tilt),in degrees.</li> <li><code>yaw</code>: The yaw angle representing the rotation around the vertical axis (left/right turn), in degrees.</li> <li><code>roll</code>: The roll angle representing the rotation around the longitudinal axis (tilting side to side), in degrees.</li> </ul> </li> </ul> <p>Note that, the ego car's data should also be included in pose data.</p>"},{"location":"Input/#bounding-box","title":"Bounding Box","text":"<p>Bounding Box data is the output of perception module (in other word, detection module).</p> <p>The Bounding Box data saved in <code>${input_data}/bboxes/bboxes-ttt.json</code>. A typical bounding box data contains</p> <pre><code>[\n    {\n        \"id\": 0,\n        \"bounding_box\": [\n            [\n                1111,\n                550\n            ],\n            [\n                1450,\n                733\n            ]\n        ]\n    },\n    ...\n]\n</code></pre> <ul> <li><code>id</code>: The detect id of NPC</li> <li><code>bounding_box</code>: The coordinates of the diagonal points of the bounding box</li> </ul> <p>The <code>id</code> is generated by perception module, it can be different with the Actors data.</p>"},{"location":"Input/#groundtruth-bouding-box-data","title":"Groundtruth Bouding Box data","text":"<p>The Groundtruth Bounding Box data is generated by the afflation of NPC location and camera settings.</p> <p>The Groundtruth Bounding Box data saved in <code>${input_data}/bboxes_gt/bboxes_gt-ttt.json</code>. It has the same format with the bounding box data.</p> <p>Note that, the <code>id</code> should same as the Actors data.</p>"},{"location":"Input/#prediction-data","title":"Prediction Data","text":"<p>The Prediction data is the output of the prediction module.</p> <p>The Prediction Data saved in <code>${input_data}/predictions/predictions-ttt.json</code>. A typical prediction data like</p> <pre><code>{\n    \"1\": {\n        \"0\": {\n            \"x\": 6.07421875,\n            \"y\": -0.012420654296875,\n            \"z\": 0.0\n        },\n        \"1\": {\n            \"x\": 6.07421875,\n            \"y\": -0.012420654296875,\n            \"z\": 0.0\n        },\n        \"2\": {\n            \"x\": 6.07421875,\n            \"y\": -0.012420654296875,\n            \"z\": 0.0\n        },\n        \"3\": {\n            \"x\": 6.07421875,\n            \"y\": -0.012420654296875,\n            \"z\": 0.0\n        },\n        ...\n    },\n    ...\n}\n</code></pre> <ul> <li><code>first-level key</code>: The id that prediction module used, commonly generated by the tracking module.<ul> <li><code>second-level key</code>: The future frame that the prediction module predict.<ul> <li><code>x</code>: The relative X-coordinate position in 3D space (in meters).</li> <li><code>y</code>: The relative Y-coordinate position in 3D space (in meters).</li> <li><code>z</code>: The relative Z-coordinate position in 3D space (in meters).</li> </ul> </li> </ul> </li> </ul> <p>The <code>id</code> can be different with the Actors data.</p>"},{"location":"Input/#adjust-prediction-data","title":"Adjust Prediction data","text":"<p>To avoid the influence of the perception module, we adjust Prediction data with perception output.</p> <p>The Adjust Prediction Data saved in <code>${input_data}/predictions_with_perception/predictions-ttt.json</code>. The format should be same as the Prediction Data</p> <p>Detail method can refer to the paper.</p>"},{"location":"Input/#waypoint-data","title":"Waypoint Data","text":"<p>The Waypoint Data is the output of the planning module.</p> <p>The Waypoint Data saved in <code>${input_data}/waypoint/waypoints-ttt.json</code>. A typical Waypoint Data like</p> <pre><code>{\n    \"0\": {\n        \"x\": -111.38533020019531,\n        \"y\": 2.820444345474243,\n        \"speed\": 0\n    },\n    \"1\": {\n        \"x\": -111.38533020019531,\n        \"y\": 2.820444345474243,\n        \"speed\": 10\n    },\n    \"2\": {\n        \"x\": -110.38533020019531,\n        \"y\": 2.8180103302001953,\n        \"speed\": 15\n    },\n    \"3\": {\n        \"x\": -109.38533020019531,\n        \"y\": 2.8155760765075684,\n        \"speed\": 20\n    },\n    ...\n}\n</code></pre> <ul> <li><code>first-level key</code>: The future frame that the planning module plan to arrive.<ul> <li><code>x</code>: The planning X-coordinate position in 3D space (in meters).</li> <li><code>y</code>: The planning Y-coordinate position in 3D space (in meters).</li> <li><code>speed</code>: The planning speed, in meters per second.</li> </ul> </li> </ul>"}]}